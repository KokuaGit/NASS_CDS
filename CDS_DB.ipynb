{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テーブル概要\n",
    "accident:  \n",
    "event:  \n",
    "gv(general vehicle):車両一般  \n",
    "ve(Exterior Vehicle):車両外部  \n",
    "vi(Interior Vehicle):車両内部  \n",
    "oa(OCCUPANT ASSESSMENT):乗員の調査  \n",
    "oi(OCCUPANT INJURY):乗員の傷害(mergeに使用できるkeyの値が同一でも傷害箇所によってレコードが増加)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最終的な作成データ\n",
    "- Crash year 2010–2015\n",
    "- Vehicle model year 2001–2015\n",
    "- Light vehicles (passenger cars, pick-ups and mini-vans) \n",
    "- Non-ejected occupants\n",
    "- Occupant age 15 or higher\n",
    "- Occupants with known injury status or fatality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ライブラリのインポート Pandasの表示設定\n",
    "同一cellに複数テーブルを表示  \n",
    "全カラムを表示  \n",
    "最大表示行数:500  \n",
    "1つのカラムの最大表示文字数:200  \n",
    "floatの有効桁数:4  \n",
    "色付き文字の出力:print(pycolor.RED + '文字列' + pycolor.END)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (roc_curve, auc, accuracy_score)\n",
    "from sklearn.linear_model import Lasso\n",
    "from IPython import embed\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "pd.options.display.float_format = '{:.4g}'.format\n",
    "class pycolor:\n",
    "    BLACK = '\\033[30m'\n",
    "    RED = '\\033[31m'\n",
    "    GREEN = '\\033[32m'\n",
    "    YELLOW = '\\033[33m'\n",
    "    BLUE = '\\033[34m'\n",
    "    PURPLE = '\\033[35m'\n",
    "    CYAN = '\\033[36m'\n",
    "    WHITE = '\\033[37m'\n",
    "    END = '\\033[0m'\n",
    "    BOLD = '\\038[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    INVISIBLE = '\\033[08m'\n",
    "    REVERCE = '\\033[07m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASS CDSデータの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.dirname(os.path.abspath('__file__'))\n",
    "file_name = ['accident', 'event', 'gv', 'oa', 'oi', 've', 'vi']\n",
    "cds_key = []\n",
    "cds = {}\n",
    "uyear = [str(x) for x in range(1, 16)]\n",
    "for year in range(2001, 2016):\n",
    "    for file in file_name:\n",
    "        if year >= 2009:\n",
    "            df = pd.read_sas(os.path.join(path, str(year), 'FormattedData', '{}.sas7bdat'.format(file)))\n",
    "        elif year >= 2001:\n",
    "            df = pd.read_sas(os.path.join(path, str(year), 'PCSAS', '{}.sas7bdat'.format(file)))\n",
    "        cds_key.append('{}_{}'.format(file, year - 2000))\n",
    "        cds['{}_{}'.format(file, year - 2000)] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.dirname(os.path.abspath('__file__'))\n",
    "expand_name = ['airbag', 'bagseat', 'childseat', 'seatloc', 'tire', 'tiredmg']\n",
    "exp_key = []\n",
    "exp = {}\n",
    "for year in range(2011, 2016):\n",
    "    for expand in expand_name:\n",
    "        try:\n",
    "            df = pd.read_sas(os.path.join(path, str(year), 'ExpandedSAS', '{}.sas7bdat'.format(expand)))\n",
    "        except FileNotFoundError:\n",
    "            df = pd.read_sas(os.path.join(path, str(year),  'ExpandedSAS', 'UNFORMATTED', '{}.sas7bdat'.format(expand)))\n",
    "        exp_key.append('{}_{}'.format(expand, year - 2000))\n",
    "        exp['{}_{}'.format(expand, year - 2000)] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特定のカラムが存在するか確認\n",
    "引数：DFを格納した辞書, 有無を確かめたいカラムのリスト, オプション:調べたいDFのkey(デフォルトは全てのDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exist_check(df_dic, check_columns, df_keys = None):\n",
    "    if df_keys is None:\n",
    "        df_keys = df_dic.keys()\n",
    "    return_df = pd.DataFrame()\n",
    "    for key in df_keys:\n",
    "        df_columns = df_dic[key].columns.values\n",
    "        check_dic = {}\n",
    "        for check_column in check_columns:\n",
    "            check_flag = 0\n",
    "            for df_column in df_columns:\n",
    "                if df_column == check_column:\n",
    "                    check_flag = 1\n",
    "            check_dic[check_column] = check_flag\n",
    "        check_df = pd.io.json.json_normalize(check_dic)\n",
    "        check_df = check_df.rename(index = {0: key})\n",
    "        return_df = pd.concat([return_df, check_df])\n",
    "    return_df.head(len(return_df))\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 同名のDFで，年毎に異なるカラムを持つか確認\n",
    "年によって異なるカラムを持つファイル名とそのカラム名を出力する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_check(df_dic):\n",
    "    df_keys = df_dic.keys()\n",
    "    return_dic = {}\n",
    "    name_list = []\n",
    "    for key in df_keys:\n",
    "        split_key = key.split('_')\n",
    "        name = split_key[0]\n",
    "        year = split_key[1]\n",
    "        df_columns = df_dic[key].columns.values.tolist()\n",
    "        if name not in name_list:\n",
    "            name_list.append(name)\n",
    "            return_dic[name] = pd.DataFrame()\n",
    "        for column in df_columns:\n",
    "            return_dic[name].loc[year, column] = 1\n",
    "    for name in name_list:\n",
    "        if return_dic[name].isnull().values.sum() != 0:\n",
    "            print(pycolor.RED + name + pycolor.END)\n",
    "            column_list = return_dic[name].columns.values.tolist()\n",
    "            column_series = return_dic[name].isnull().any()\n",
    "            for column in column_list:\n",
    "                if column_series[column] == True:\n",
    "                    print(column)\n",
    "    return return_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  テーブル間で重複するカラムの出力\n",
    "デフォルトで重複は15年について調べる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_column(df_dic, conf_year = '15'):\n",
    "    df_keys = df_dic.keys() \n",
    "    column_dic = {}\n",
    "    name_list = []\n",
    "    duplicate_list = []\n",
    "    return_df = pd.DataFrame()\n",
    "    for key in df_keys:\n",
    "        name = key.split('_')[0]\n",
    "        year = key.split('_')[1]\n",
    "        if year == conf_year:\n",
    "            column_dic[name] = df_dic[key].columns.values.tolist()\n",
    "            name_list.append(name)\n",
    "    for name in name_list:\n",
    "        duplicate_list.extend(column_dic[name])\n",
    "    duplicate_list = [x for x in set(duplicate_list) if duplicate_list.count(x) > 1]\n",
    "    for name in name_list:\n",
    "        for column in column_dic[name]:\n",
    "            if column in duplicate_list:\n",
    "                return_df.loc[name, column] = 1\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重複したレコードの抽出\n",
    "引数：DF辞書, DFのkey, 重複判定column(リスト)   \n",
    "重複判定columnを先頭にしたDFを出力  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate(df_dic, dic_key, df_key):\n",
    "    df = df_dic[dic_key]\n",
    "    df = df[df.duplicated(subset = df_key, keep = False)]\n",
    "    columns = list(df.columns.values)\n",
    "    for column in df_key:\n",
    "        columns.remove(column)\n",
    "    return df.loc[:, df_key + columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds_column = year_check(cds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds_column['oa'][['CHOWUSED', 'LATCHDES', 'LATCHUSE', 'POSPRES', 'POSUSE', 'POSGUIDE']]\n",
    "cds_column['ve'][['TOWRES']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds['accident_11'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds['event_11'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds['gv_15'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds['gv_15'].describe()\n",
    "len(cds['gv_15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds['oi_11'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds['oa_15'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.merge(cds['oa_10'], cds['gv_10'], on = ['CASEID', 'CASENO', 'PSU', 'RATWGT', 'STRATIF', 'VERSION', 'VEHNO'], how = 'inner'))\n",
    "print(len(cds['gv_10']), len(cds['oa_10']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds['ve_11'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds['vi_11'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整数の値が入っているはずなのに小数点以下の値が入っているもの，同じ値なのにpython内部で別の値として認識されているものを修正\n",
    "## 複数のテーブルで重複しているが利用しないカラムの削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['PSU', 'VEHNO']:\n",
    "    for y in uyear:\n",
    "        for og in ['oa', 'gv', 've', 'vi']:\n",
    "            cds['{}_{}'.format(og, y)][col] = cds['{}_{}'.format(og, y)][col].astype(np.int64)\n",
    "        if col !=  'VEHNO':\n",
    "            og = 'accident'\n",
    "            cds['{}_{}'.format(og, y)][col] = cds['{}_{}'.format(og, y)][col].astype(np.int64)\n",
    "            \n",
    "for y in uyear:\n",
    "    y  = str(y)\n",
    "    cds['accident_{}'.format(y)]['VEHFORMS'] = cds['accident_{}'.format(y)]['VEHFORMS'].astype(np.int64)\n",
    "\n",
    "for col in ['CASENO', 'RATWGT', 'STRATIF', 'VERSION']:\n",
    "    for y in range(10, 16):\n",
    "        for og in ['oa', 'gv', 've', 'vi', 'accident', 'event', 'oi']:\n",
    "            cds['{}_{}'.format(og, y)] = cds['{}_{}'.format(og, y)].drop(col, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テーブル，年毎のレコード数を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in uyear:\n",
    "    print(year)\n",
    "    for file in file_name:\n",
    "        print('{}:'.format(file) + str(len(cds['{}_{}'.format(file, year)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 年毎に同一のカラムを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in uyear:\n",
    "    print(year)\n",
    "    same_column(cds, str(year)).head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テーブル毎の結合keyを宣言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_key = {}\n",
    "for file in file_name:\n",
    "    if file == 'accident' or file == 'event':\n",
    "        merge_key[file] =  ['CASEID', 'PSU']\n",
    "    if file == 'gv' or file == 've' or file == 'vi':\n",
    "        merge_key[file] = ['CASEID', 'PSU', 'VEHNO']\n",
    "    if file == 'oa' or file == 'oi':\n",
    "        merge_key[file] = ['CASEID', 'PSU', 'VEHNO', 'OCCNO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 同一の結合keyに対して重複しているレコードを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_dic = {}\n",
    "for file in file_name:\n",
    "    print(file)\n",
    "    dup_dic[file] = duplicate(cds, '{}_10'.format(file), merge_key[file])\n",
    "    dup_dic[file].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テーブルの結合\n",
    "oi,eventテーブルを除き,2010~2015年のデータをそれぞれ結合する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds_merge = {}\n",
    "for year in uyear:\n",
    "    cds_merge[year] = cds['oa_{}'.format(year)]\n",
    "    for file in [x for x in file_name if not (x == 'oa' or x == 'oi' or x == 'event')]:\n",
    "        if file != 'gv':\n",
    "            cds_merge[year] = pd.merge(cds_merge[year], cds['{}_{}'.format(file, year)], on = merge_key[file], how = 'left')\n",
    "        else:\n",
    "            cds_merge[year] = pd.merge(cds_merge[year], cds['{}_{}'.format(file, year)], on = merge_key[file], how = 'inner')\n",
    "    print(year)\n",
    "    print('oa_length:' + str(len(cds['oa_{}'.format(year)])))\n",
    "    print('merge_length:' + str(len(cds_merge[year])))\n",
    "    cds_merge[year].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結合後の編集用辞書データの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds_prepro = {}\n",
    "for year in uyear:\n",
    "    cds_prepro[year] = cds_merge[year]\n",
    "    print(year,len(cds_prepro[year]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用するカラムを抽出\n",
    "pcol:目的変数  \n",
    "CASEID, PSU, VEHNO: 結合キー  \n",
    "VEHFORMS: 事故に関わった車両数  \n",
    "BODYTYPE, CURBWGT, TRAVELSP: 自車データ  \n",
    "PDOF1, GAD1, SHL1: 衝突箇所データ(角度, 位置(前後左右上下), 位置(GAD1と共に使うことで前後左右の面をそれぞれ3分割できる))  \n",
    "otbdytyp, otvehwgt: 相手車両データ  \n",
    "BAGAVAIL, PARUSE: エアバッグの有無・シートベル着用の有無  \n",
    "AGE, SEX, HEIGHT, WEIGHT: 乗員データ:一般に重症度に大きな影響があると言われる4つの要素  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcol = 'MAIS'\n",
    "use_col = [pcol, \\\n",
    "           'CASEID', 'PSU', 'VEHNO', \\\n",
    "           'VEHFORMS', \\\n",
    "           'BODYTYPE', 'CURBWGT', 'TRAVELSP', \\\n",
    "           'PDOF1', 'GAD1', \\\n",
    "           'otbdytyp', 'otvehwgt', \\\n",
    "           'BAGAVAIL', 'PARUSE', \\\n",
    "           'AGE', 'SEX', 'HEIGHT', 'WEIGHT']\n",
    "for year in uyear:\n",
    "    cds_prepro[year] = cds_prepro[year][use_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## もう一方の車両の速度を示すカラムを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in uyear:\n",
    "    sp = cds_prepro[year][['CASEID', 'PSU', 'VEHNO', 'TRAVELSP']]\n",
    "    sp = sp.drop_duplicates(subset = ['CASEID', 'PSU', 'VEHNO'])\n",
    "    sp1 = sp.query('VEHNO == 1')\n",
    "    sp1 = sp1.drop('VEHNO', axis  = 1)\n",
    "    sp1 = sp1.rename(columns = {'TRAVELSP': 'SP1'})\n",
    "    sp2 = sp.query('VEHNO == 2')\n",
    "    sp2 = sp2.drop('VEHNO', axis  = 1)\n",
    "    sp2 = sp2.rename(columns = {'TRAVELSP': 'SP2'})\n",
    "    sp = pd.merge(sp1, sp2, on = ['CASEID', 'PSU'], how = 'inner')\n",
    "    v1o = sp[['CASEID', 'PSU', 'SP2']]\n",
    "    v1o['VEHNO'] = 1\n",
    "    v2o = sp[['CASEID', 'PSU', 'SP1']]\n",
    "    v2o['VEHNO'] = 2   \n",
    "    cds_prepro[year] = pd.merge(cds_prepro[year], v1o, on = ['CASEID', 'PSU', 'VEHNO'], how = 'left')\n",
    "    cds_prepro[year] = pd.merge(cds_prepro[year], v2o, on = ['CASEID', 'PSU', 'VEHNO'], how = 'left')\n",
    "    cds_prepro[year] = cds_prepro[year].fillna({'SP1': 0,  'SP2':  0})\n",
    "    cds_prepro[year]['otbsp'] = cds_prepro[year]['SP1'] + cds_prepro[year]['SP2'] \n",
    "    cds_prepro[year] = cds_prepro[year].drop(['SP1', 'SP2'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NANを含むレコードを削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in uyear:\n",
    "    print(year)\n",
    "    print('削除前：', len(cds_prepro[year]))\n",
    "    cds_prepro[year] = cds_prepro[year].dropna(how = 'any')\n",
    "    print('削除後：', len(cds_prepro[year]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASEID以外をintに"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_col = [x for x in use_col if x != 'CASEID' and x != 'GAD1']\n",
    "for col in use_col:\n",
    "    for year in uyear:\n",
    "        cds_prepro[year][col] = cds_prepro[year][col].astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car to Carの事故に限定\n",
    "2台の事故のみに変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in uyear:\n",
    "    cds_prepro[year] = cds_prepro[year].query('VEHFORMS == 2')\n",
    "    print(year, len(cds_prepro[year]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 値は入っているがUnknownを示す値が入っているものを削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in uyear:\n",
    "    print(pycolor.RED + year + pycolor.END)\n",
    "    print(len(cds_prepro[year]))\n",
    "    cds_prepro[year] = cds_prepro[year].query('TRAVELSP < 777 and CURBWGT < 998 and GAD1 != 9 and PDOF1 < 998 and otvehwgt < 998 and PARUSE != 10 and otbsp < 777')\n",
    "    print(len(cds_prepro[year]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## シートベルト使用者とエアバッグ利用可能だった乗員に限定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in uyear:\n",
    "    print(pycolor.RED + year + pycolor.END)\n",
    "    print(len(cds_prepro[year]))\n",
    "    cds_prepro[year] = cds_prepro[year].query('BAGAVAIL == 1 and PARUSE != 0')\n",
    "    print(len(cds_prepro[year]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 車両毎にMAISの最大値のみ残す\n",
    "MAISでソートし, VEHNOが重複しているレコードを上にあるものを残して削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in uyear:\n",
    "    print(pycolor.RED + year + pycolor.END)\n",
    "    print(len(cds_prepro[year]))\n",
    "    cds_prepro[year] = cds_prepro[year].sort_values(by = pcol, ascending = False)\n",
    "    cds_prepro[year] = cds_prepro[year].drop_duplicates(subset = ['CASEID', 'PSU', 'VEHNO'])\n",
    "    print(len(cds_prepro[year]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結合や絞り込みに必要だったカラムの除外"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in uyear:\n",
    "    cds_prepro[year] = cds_prepro[year].drop(['CASEID', 'PSU', 'VEHNO', 'BAGAVAIL', 'PARUSE', 'VEHFORMS'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 性別を男女にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in uyear:\n",
    "    cds_prepro[year].loc[cds_prepro[year]['SEX'] >= 2, 'SEX']  = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ダミー変数に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = pd.concat([cds_prepro['1'], cds_prepro['2'], cds_prepro['3'], cds_prepro['4'], cds_prepro['5'], cds_prepro['6'], cds_prepro['7'], cds_prepro['8'], cds_prepro['9'], cds_prepro['10'], cds_prepro['11'], cds_prepro['12'], cds_prepro['13'], cds_prepro['14'], cds_prepro['15']])\n",
    "dummy = pd.get_dummies(dummy, drop_first = True, columns = ['BODYTYPE', 'GAD1', 'otbdytyp', 'SEX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最終的なデータ数と元のデータ数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 0\n",
    "for year in uyear:\n",
    "    length += len(cds['gv_{}'.format(year)])\n",
    "print('元データ:', length)\n",
    "print('最終：',len(dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テストデータと訓練データに分割\n",
    "時系列を考慮して15年のデータをテストデータとする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_15 = dummy[len(dummy) - len(cds_prepro['15']):]\n",
    "dummy_b14 = dummy[:len(dummy) - len(cds_prepro['15'])]\n",
    "X_train = dummy_b14.drop([pcol], axis = 1)\n",
    "y_train = dummy_b14[pcol]\n",
    "X_test = dummy_15.drop([pcol], axis = 1)\n",
    "y_test = dummy_15[pcol]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ランダムフォレストで分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators = 1000, random_state = 0)\n",
    "forest.fit(X_train, y_train)\n",
    "predict = forest.predict(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predict, pos_label = 1)\n",
    "auc(fpr, tpr)\n",
    "accuracy_score(predict, y_test)\n",
    "fti = forest.feature_importances_\n",
    "columns = dummy.columns.values\n",
    "columns = list(columns)\n",
    "columns.remove('MAIS')\n",
    "print('Feature Importance')\n",
    "for i, col in enumerate(columns):\n",
    "    print(col, ':', fti[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15年の要約統計量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds_prepro['15'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds_prepro['15'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp_column = year_check(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pd.DataFrame(exp_column['airbag']['RECTYPE'])\n",
    "pd.DataFrame(exp_column['bagseat']['RECTYPE'])\n",
    "exp_column['childseat'][['STRATIF','VERSION']]\n",
    "exp_column['seatloc'][['VERSION' ,'RECTYPE' ,'POSGUIDE']]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp['airbag_11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for expand in expand_name:\n",
    "    print('{}:'.format(expand) + str(len(exp['{}_15'.format(expand)])))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same_column(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for expand in expand_name:\n",
    "    print('{}:'.format(expand) + str(len(exp['{}_15'.format(expand)])))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same_column(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  以下挙動確認用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoge = pd.DataFrame({'key1':[1, 1, 1],\n",
    "                     'key2':[3,3,3],\n",
    "                     'key3':[1, 3, 3],\n",
    "                     'data_x':['a', 'b', 'c']})\n",
    "hoge.head()\n",
    "hoge2 = pd.DataFrame({'key1':[1, 1, 3],\n",
    "                      'key2':[3, 3, 5],\n",
    "                      'key3':[1, 3, 4],\n",
    "                      'data_y':['d', 'e', 'f']})\n",
    "hoge2.head()\n",
    "hoge3 = pd.DataFrame({'key1':[1],\n",
    "                      'data':['g']})\n",
    "hoge3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(hoge, hoge3, on = 'key1').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoge3 = pd.merge(hoge, hoge2, on = 'key1', how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoge3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoge3['key2_x'] = hoge3['key2_x'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoge3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoge['data_x'] = hoge['data_x'].replace('a', 'e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.merge(hoge, hoge2, on = ['key1', 'key2'], how = 'outer')\n",
    "#pd.merge(hoge, hoge2, on = ['key1', 'key2'], how = 'inner')\n",
    "pd.merge(hoge, hoge2, on = ['key1', 'key2', 'key3'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(hoge, hoge2, on = 'key1', how = 'inner')\n",
    "test.head()\n",
    "test = pd.merge(test, hoge3, on = 'key1', how = 'inner')\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hogehoge = pd.DataFrame()\n",
    "pd.merge(hoge, hogehoge, on = ['key1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用するか不明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量のドロップ\n",
    "結合用の特徴量・AISを元にした特徴量・年によってデータが存在しない特徴量をドロップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cds_prepro = {}\n",
    "drop_columns = ['CASEID', 'CASENO', 'VEHNO', 'OCCNO', 'RATWGT', 'STRATIF', 'VERSION', 'AAIS',\\\n",
    "                'AAIS08', 'VAIS', 'VAIS08', 'MAIS', 'MAIS08', 'INJNUM08', 'ISS08', 'TOWRES', \\\n",
    "                'VIN', 'AINJSER', 'AINJSER8', 'AINJURED', 'AINJURD8', 'VINJSER', 'VINJSER8', \\\n",
    "                'VINJURED', 'VINJURD8', 'INJNUM', 'LATCHDES', 'LATCHUSE', 'POSPRES', 'POSUSE', \\\n",
    "                'POSGUIDE','CHOWUSED', 'FUELTYP1', 'FUELTYP2']#INJSEVは警察の報告でありAISデータを使用していない\n",
    "for year in range(10, 16):\n",
    "    year = str(year)\n",
    "    cds_prepro[year] = cds_merge[year]\n",
    "    year_columns = cds_prepro[year].columns.values.tolist()\n",
    "    for column in drop_columns:\n",
    "        if column in year_columns:\n",
    "            cds_prepro[year] = cds_prepro[year].drop(columns = [column])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ISSデータが存在しないレコードのドロップ\n",
    "推定対象のISSが存在しないレコードのドロップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ISSのnanをdropし，年毎のレコード数をprint\n",
    "'''\n",
    "for year in range(10, 16):\n",
    "    year = str(year)\n",
    "    cds_prepro[year] = cds_prepro[year].dropna(subset = ['ISS'])\n",
    "    print(str(year) + ':' + str(len(cds_prepro[year])))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 論文と年以外の条件を同じに\n",
    "Vehicle Modelの0~490が相当"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "q_column = ['AGE', 'EJECTION', 'MODEL', 'MODELYR']\n",
    "query = ['AGE >= 15', 'EJECTION == 0', '0 <= MODEL <= 490', '2001 <= MODELYR <= 2015']\n",
    "for year in range(10, 16):\n",
    "    year =  str(year)\n",
    "    print(pycolor.GREEN + 'year:' + year + pycolor.END)\n",
    "    print('レコード数:', len(cds_prepro[year]))\n",
    "    for col, que in zip(q_column, query):\n",
    "        print(pycolor.RED +'column:' + col + pycolor.END)\n",
    "        print('NaN:', cds_prepro[year][col].isnull().sum())\n",
    "        print('クエリによるレコードの減少数(' + que + '):', len(cds_prepro[year]) - len(cds_prepro[year].query(que)))\n",
    "    print()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "query = ['AGE >= 15', 'EJECTION == 0']#, '0 <= MODEL <= 490', '2001 <= MODELYR <= 2015']\n",
    "for que in query:\n",
    "    print('query:', que)\n",
    "    print('クエリによる減少数(残ったレコード数)')\n",
    "    for year in range(10, 16):\n",
    "        year = str(year)\n",
    "        before = len(cds_prepro[year])\n",
    "        cds_prepro[year] = cds_prepro[year].query(que)\n",
    "        print(' ', year, ':', str(before - len(cds_prepro[year])), '({})'.format(len(cds_prepro[year])))\n",
    "        #print(' ', year, ':', str(before - len(cds_prepro[year].query(que))))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cds_prepro['15']['VEHWGT'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カラム名をCSVに出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "col = cds_prepro['15'].query('MODEL > 500')\n",
    "path = os.path.dirname(os.path.abspath('__file__'))\n",
    "col.to_csv(os.path.join(path, 'column.csv'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 値の変更\n",
    "同一のものを指しているにも関わらず年によって値が違うものを修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for year in range(10, 16):\n",
    "    year = str(year)\n",
    "    cds_prepro[year]['CLIMATE'] = cds_prepro[year]['CLIMATE'].replace('13', '20') \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
