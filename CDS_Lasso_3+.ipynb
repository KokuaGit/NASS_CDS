{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テーブル概要\n",
    "accident:  \n",
    "event:  \n",
    "gv(general vehicle):車両一般  \n",
    "ve(Exterior Vehicle):車両外部  \n",
    "vi(Interior Vehicle):車両内部  \n",
    "oa(OCCUPANT ASSESSMENT):乗員の調査  \n",
    "oi(OCCUPANT INJURY):乗員の傷害(mergeに使用できるkeyの値が同一でも傷害箇所によってレコードが増加)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最終的な作成データ\n",
    "- Crash year 2010–2015\n",
    "- Vehicle model year 2001–2015\n",
    "- Light vehicles (passenger cars, pick-ups and mini-vans) \n",
    "- Non-ejected occupants\n",
    "- Occupant age 15 or higher\n",
    "- Occupants with known injury status or fatality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ライブラリのインポート Pandasの表示設定\n",
    "同一cellに複数テーブルを表示  \n",
    "全カラムを表示  \n",
    "最大表示行数:500  \n",
    "1つのカラムの最大表示文字数:200  \n",
    "floatの有効桁数:4  \n",
    "色付き文字の出力:print(pycolor.RED + '文字列' + pycolor.END)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import  confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (roc_curve, auc, accuracy_score)\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from IPython import embed\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "pd.options.display.float_format = '{:.4g}'.format\n",
    "class pycolor:\n",
    "    BLACK = '\\033[30m'\n",
    "    RED = '\\033[31m'\n",
    "    GREEN = '\\033[32m'\n",
    "    YELLOW = '\\033[33m'\n",
    "    BLUE = '\\033[34m'\n",
    "    PURPLE = '\\033[35m'\n",
    "    CYAN = '\\033[36m'\n",
    "    WHITE = '\\033[37m'\n",
    "    END = '\\033[0m'\n",
    "    BOLD = '\\038[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    INVISIBLE = '\\033[08m'\n",
    "    REVERCE = '\\033[07m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASS CDSデータの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.dirname(os.path.abspath('__file__'))\n",
    "file_name = ['accident', 'event', 'gv', 'oa', 'oi', 've', 'vi']\n",
    "cds_key = []\n",
    "cds = {}\n",
    "uyear = [str(x) for x in range(1, 16)]\n",
    "for year in range(2001, 2016):\n",
    "    for file in file_name:\n",
    "        if year >= 2009:\n",
    "            df = pd.read_sas(os.path.join(path, str(year), 'FormattedData', '{}.sas7bdat'.format(file)))\n",
    "        elif year >= 2001:\n",
    "            df = pd.read_sas(os.path.join(path, str(year), 'PCSAS', '{}.sas7bdat'.format(file)))\n",
    "        cds_key.append('{}_{}'.format(file, year - 2000))\n",
    "        cds['{}_{}'.format(file, year - 2000)] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整数の値が入っているはずなのに小数点以下の値が入っているもの，同じ値なのにpython内部で別の値として認識されているものを修正\n",
    "## 複数のテーブルで重複しているが利用しないカラムの削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['PSU', 'VEHNO']:\n",
    "    for y in uyear:\n",
    "        for og in ['oa', 'gv', 've', 'vi']:\n",
    "            cds['{}_{}'.format(og, y)][col] = cds['{}_{}'.format(og, y)][col].astype(np.int64)\n",
    "        if col !=  'VEHNO':\n",
    "            og = 'accident'\n",
    "            cds['{}_{}'.format(og, y)][col] = cds['{}_{}'.format(og, y)][col].astype(np.int64)\n",
    "            \n",
    "for y in uyear:\n",
    "    y  = str(y)\n",
    "    cds['accident_{}'.format(y)]['VEHFORMS'] = cds['accident_{}'.format(y)]['VEHFORMS'].astype(np.int64)\n",
    "\n",
    "for col in ['CASENO', 'RATWGT', 'STRATIF', 'VERSION']:\n",
    "    for y in range(10, 16):\n",
    "        for og in ['oa', 'gv', 've', 'vi', 'accident', 'event', 'oi']:\n",
    "            cds['{}_{}'.format(og, y)] = cds['{}_{}'.format(og, y)].drop(col, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テーブル，年毎のレコード数を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in uyear:\n",
    "    print(year)\n",
    "    for file in file_name:\n",
    "        print('{}:'.format(file) + str(len(cds['{}_{}'.format(file, year)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テーブル毎の結合keyを宣言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_key = {}\n",
    "for file in file_name:\n",
    "    if file == 'accident' or file == 'event':\n",
    "        merge_key[file] =  ['CASEID', 'PSU']\n",
    "    if file == 'gv' or file == 've' or file == 'vi':\n",
    "        merge_key[file] = ['CASEID', 'PSU', 'VEHNO']\n",
    "    if file == 'oa' or file == 'oi':\n",
    "        merge_key[file] = ['CASEID', 'PSU', 'VEHNO', 'OCCNO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テーブルの結合\n",
    "oi,eventテーブルを除き,2010~2015年のデータをそれぞれ結合する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds_merge = {}\n",
    "for year in uyear:\n",
    "    cds_merge[year] = cds['oa_{}'.format(year)]\n",
    "    for file in [x for x in file_name if not (x == 'oa' or x == 'oi' or x == 'event')]:\n",
    "        if file != 'gv':\n",
    "            cds_merge[year] = pd.merge(cds_merge[year], cds['{}_{}'.format(file, year)], on = merge_key[file], how = 'left')\n",
    "        else:\n",
    "            cds_merge[year] = pd.merge(cds_merge[year], cds['{}_{}'.format(file, year)], on = merge_key[file], how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 編集用辞書データの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds_prepro = {}\n",
    "for year in uyear:\n",
    "    cds_prepro[year] = cds_merge[year]\n",
    "    print(year,len(cds_prepro[year]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car to Carの事故に限定\n",
    "2台の事故のみに変更  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in uyear:\n",
    "    cds_prepro[year] = cds_prepro[year].query('VEHFORMS == 2')\n",
    "    print(year, len(cds_prepro[year]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## もう一方の車両の速度を示すカラムを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#合ってるか怪しい\n",
    "for year in uyear:\n",
    "    sp = cds_prepro[year][['CASEID', 'PSU', 'VEHNO', 'DVTOTAL']]\n",
    "    sp = sp.drop_duplicates(subset = ['CASEID', 'PSU', 'VEHNO'])\n",
    "    sp1 = sp.query('VEHNO == 1')\n",
    "    sp1 = sp1.drop('VEHNO', axis  = 1)\n",
    "    sp1 = sp1.rename(columns = {'DVTOTAL': 'SP1'})\n",
    "    sp2 = sp.query('VEHNO == 2')\n",
    "    sp2 = sp2.drop('VEHNO', axis  = 1)\n",
    "    sp2 = sp2.rename(columns = {'DVTOTAL': 'SP2'})\n",
    "    sp = pd.merge(sp1, sp2, on = ['CASEID', 'PSU'], how = 'inner')\n",
    "    v1o = sp[['CASEID', 'PSU', 'SP2']]\n",
    "    v1o['VEHNO'] = 1\n",
    "    v2o = sp[['CASEID', 'PSU', 'SP1']]\n",
    "    v2o['VEHNO'] = 2   \n",
    "    cds_prepro[year] = pd.merge(cds_prepro[year], v1o, on = ['CASEID', 'PSU', 'VEHNO'], how = 'left')\n",
    "    cds_prepro[year] = pd.merge(cds_prepro[year], v2o, on = ['CASEID', 'PSU', 'VEHNO'], how = 'left')\n",
    "    cds_prepro[year] = cds_prepro[year].fillna({'SP1': 0,  'SP2':  0})\n",
    "    cds_prepro[year]['otbsp'] = cds_prepro[year]['SP1'] + cds_prepro[year]['SP2'] \n",
    "    cds_prepro[year] = cds_prepro[year].drop(['SP1', 'SP2'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## エアバッグ利用可能・シートベルト着用・15歳以上に限定\n",
    "ベルトは3点ベルトのみ着用しているとみなす"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in uyear:\n",
    "    cds_prepro[year] = cds_prepro[year].query('MAIS <= 6 & PARUSE == 4 & AGE >= 15')\n",
    "    print(year, len(cds_prepro[year]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用可能な特徴量を全て抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcol = 'MAIS'\n",
    "use_col = [pcol, \\\n",
    "           'CASEID', 'PSU', 'VEHNO', \\\n",
    "           'YEAR', 'MONTH', 'TIME', 'DAYWEEK', 'DVTOTAL', \\\n",
    "           'MODEL', 'MODELYR', 'BODYTYPE', 'ALIGNMNT', 'ANTILOCK', 'CARGOWGT', 'CONDTREE', 'CURBWGT', 'FOURWHDR', 'FRTWHLDR', 'FUELCODE', 'LGTCOND', 'PROFILE', 'RELINTER', 'RESTYPE', 'SPLIMIT', 'SURCOND', 'SURTYPE', 'TRAFCONT', 'TRAFFLOW', 'TRAVELSP', 'TRCTLFCT', 'VEHTYPE', 'VEHUSE', 'VEHWGT', 'WGTCDTR', 'WHLDRWHL', 'otbdytyp', 'otvehwgt', \\\n",
    "           'FUELCAP1', 'FUELCAP2', 'FUELLOC1', 'FUELLOC2', 'FUELTYP1', 'FUELTYP2','FUELTNK1', 'FUELTNK2', 'ORIGAVTW', 'PDOF1', 'SHL1', 'WHEELBAS', \\\n",
    "           'GLTYPWS', 'GLTYPLF', 'GLTYPLR', 'GLTYPRF', 'GLTYPRR', 'GLTYPBL', 'GLTYPRUF', 'GLTYPOTH', 'GLPREWS', 'GLPRELF', 'GLPRELR', 'GLPRERF', 'GLPRERR', 'GLPREBL', 'GLPRERUF', 'GLPREOTH', 'COLUMTYP', 'COLMTELE', 'COLMTILT', 'ODOMETER', 'ADAPTEQ', \\\n",
    "           'AGE', 'BAGAVAIL', 'BAGAVOTH', 'BAGMAINT', 'BAGTYPE', 'BELTANCH', 'HEIGHT', 'MANAVAIL', 'MANUSE', 'POSTURE',  'ROLE', 'SEATPOS', 'SEATRACK', 'SEATTYPE', 'SEX', 'STORIENT', 'WEIGHT', \\\n",
    "           'otbsp']\n",
    "for year in uyear:\n",
    "    cds_prepro[year] = cds_prepro[year][use_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1~15年の前データ確認用データフレームの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns  = use_col.remove('otbsp')\n",
    "cds_all  = cds_merge['1'][use_col]\n",
    "for year in range(2, 16):\n",
    "    year = str(year)\n",
    "    cds_all = pd.concat([cds_all, cds_merge[year][use_col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cds_all.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SURCONDの年毎に違う値を修正\n",
    "2009年以降がより細分化されて記録されているので、2008年の基準に統一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(9, 16):\n",
    "    year = str(year)\n",
    "    cds_prepro[year].loc[cds_prepro[year]['SURCOND'] == 4, 'SURCOND'] =  3\n",
    "    cds_prepro[year].loc[cds_prepro[year]['SURCOND'] == 5, 'SURCOND'] = 4\n",
    "    cds_prepro[year].loc[(cds_prepro[year]['SURCOND'] >= 7)  & (cds_prepro[year]['SURCOND'] <= 9), 'SURCOND'] = 5\n",
    "    cds_prepro[year].loc[(cds_prepro[year]['SURCOND'] > 87) | (cds_prepro[year]['SURCOND']  == 6), 'SURCOND'] = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIS → MAIS3+, TIME → 時間帯,  SEX → 性別・妊娠の有無"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for year in uyear:\n",
    "    cds_prepro[year].loc[cds_prepro[year][pcol] < 3, 'MAIS3+'] = 0\n",
    "    cds_prepro[year].loc[cds_prepro[year][pcol] >= 3, 'MAIS3+'] = 1\n",
    "    cds_prepro[year].loc[(cds_prepro[year]['TIME'] >= 600) & (cds_prepro[year]['TIME'] < 900), 'TZONE'] = 1\n",
    "    cds_prepro[year].loc[(cds_prepro[year]['TIME'] >= 900) & (cds_prepro[year]['TIME'] < 1200), 'TZONE'] = 2\n",
    "    cds_prepro[year].loc[(cds_prepro[year]['TIME'] >= 1200) & (cds_prepro[year]['TIME'] < 1500), 'TZONE'] = 3\n",
    "    cds_prepro[year].loc[(cds_prepro[year]['TIME'] >= 1500) & (cds_prepro[year]['TIME'] < 1800), 'TZONE'] = 4\n",
    "    cds_prepro[year].loc[(cds_prepro[year]['TIME'] >= 1800) & (cds_prepro[year]['TIME'] < 2100), 'TZONE'] = 5\n",
    "    cds_prepro[year].loc[cds_prepro[year]['TIME'] >= 2100, 'TZONE'] = 6\n",
    "    cds_prepro[year].loc[cds_prepro[year]['TIME'] < 300, 'TZONE'] = 7\n",
    "    cds_prepro[year].loc[(cds_prepro[year]['TIME'] >= 300) & (cds_prepro[year]['TIME'] < 600), 'TZONE'] = 8\n",
    "    cds_prepro[year] = cds_prepro[year].drop(['TIME'], axis = 1)\n",
    "    cds_prepro[year].loc[cds_prepro[year]['SEX'] > 2, 'PREG'] = 1\n",
    "    cds_prepro[year].loc[cds_prepro[year]['SEX'] >= 2, 'SEX'] = 0\n",
    "    cds_prepro[year] = cds_prepro[year].fillna({'PREG' : 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 車両毎にMAISの最大値のみ残す\n",
    "MAISでソートし, VEHNOが重複しているレコードを上にあるものを残して削除  \n",
    "MAIS3+のカラムを作成したのでMAISのカラムはドロップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for year in uyear:\n",
    "    print(pycolor.RED + year + pycolor.END)\n",
    "    print(len(cds_prepro[year]))\n",
    "    cds_prepro[year] = cds_prepro[year].sort_values(by = pcol, ascending = False)\n",
    "    cds_prepro[year] = cds_prepro[year].drop_duplicates(subset = ['CASEID', 'PSU', 'VEHNO'])\n",
    "    cds_prepro[year] = cds_prepro[year].drop([pcol, 'PSU', 'CASEID', 'VEHNO'], axis = 1)\n",
    "    print(len(cds_prepro[year]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1~15年を結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = cds_prepro['1']\n",
    "for year in range(2, 15):\n",
    "    year = str(year)\n",
    "    X_train = pd.concat([X_train, cds_prepro[year]])\n",
    "X_test = cds_prepro['15']\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整数値に変換し直す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test['ADAPTEQ'] = X_test['ADAPTEQ'].astype(np.int64)\n",
    "X_test['COLUMTYP'] = X_test['COLUMTYP'].astype(np.int64)\n",
    "X_test['SEATRACK'] = X_test['SEATRACK'].astype(np.int64)\n",
    "X_train['ADAPTEQ'] = X_train['ADAPTEQ'].astype(np.int64)\n",
    "X_train['COLUMTYP'] = X_train['COLUMTYP'].astype(np.int64)\n",
    "X_train['SEATRACK'] = X_train['SEATRACK'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtype = X_train.dtypes\n",
    "for i in X_train.columns:\n",
    "    if dtype[i] == 'object':\n",
    "        label, unique = pd.factorize(X_train[i])\n",
    "        X_train[i] = label\n",
    "        X_train.loc[X_train[i] == -1, i] = pd.np.nan\n",
    "        label, unique = pd.factorize(X_test[i])\n",
    "        X_test[i] = label\n",
    "        X_test.loc[X_test[i] == -1, i] = pd.np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaNを中央値で置換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds_md = X_train.median()\n",
    "X_train = X_train.fillna(cds_md)\n",
    "X_test = X_test.fillna(cds_md)\n",
    "cds_lasso = pd.concat([X_train, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 説明変数と目的変数に分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train['MAIS3+']\n",
    "X_train = X_train.drop(['MAIS3+'], axis = 1)\n",
    "y_test = X_test['MAIS3+']\n",
    "X_test = X_test.drop(['MAIS3+'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ランダムフォレストで推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clabel = {0:1, 1:500}\n",
    "grid_param = {'n_estimators': [500], 'max_depth': [10, 20, 30]}\n",
    "forest = GridSearchCV(RandomForestClassifier(random_state = 0, class_weight = clabel), grid_param, cv = 5, scoring = 'roc_auc')\n",
    "forest.fit(X_train, y_train)\n",
    "predict = forest.predict(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predict, pos_label = 1)\n",
    "print('best parameter:', forest.best_params_)\n",
    "print('auc:', auc(fpr, tpr))\n",
    "print('accuracy', accuracy_score(predict, y_test))\n",
    "fti = forest.best_estimator_.feature_importances_\n",
    "columns = list(X_train.columns.values)\n",
    "im_df = pd.DataFrame({'Feature':columns,\n",
    "                     'importance':fti})\n",
    "im_df = im_df.sort_values('importance', ascending = False)\n",
    "im_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(predict).count(0)\n",
    "list(predict).count(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ダミー変数化 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_col = ['DAYWEEK', 'MONTH',  \\\n",
    "             'MODEL', 'BODYTYPE', 'ALIGNMNT', 'ANTILOCK', 'CONDTREE', 'FOURWHDR', 'FRTWHLDR', 'FUELCODE', 'LGTCOND', 'PROFILE', 'RELINTER', 'RESTYPE', 'SURCOND', 'SURTYPE', 'TRAFCONT', 'TRAFFLOW', 'TRCTLFCT', 'VEHTYPE', 'VEHUSE', 'otbdytyp',\\\n",
    "             'FUELCAP1', 'FUELCAP2', 'FUELLOC1', 'FUELLOC2', 'FUELTYP1', 'FUELTYP2', 'FUELTNK1', 'FUELTNK2', 'PDOF1', 'SHL1', \\\n",
    "             'GLTYPWS', 'GLTYPLF', 'GLTYPLR', 'GLTYPRF', 'GLTYPRR', 'GLTYPBL', 'GLTYPRUF', 'GLTYPOTH', 'GLPREWS', 'GLPRELF', 'GLPRELR', 'GLPRERF', 'GLPRERR', 'GLPREBL', 'GLPRERUF', 'GLPREOTH', 'COLUMTYP', 'COLMTELE', 'COLMTILT', 'ADAPTEQ', \\\n",
    "             'BAGAVAIL', 'BAGAVOTH', 'BAGMAINT', 'BAGTYPE', 'BELTANCH', 'MANAVAIL', 'MANUSE',  'POSTURE',  'ROLE', 'SEATPOS', 'SEATRACK', 'SEATTYPE', 'STORIENT']\n",
    "cds_dummy = pd.get_dummies(cds_lasso, drop_first = False, columns  = dummy_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テストデータと訓練データに分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds_test = cds_dummy.query('YEAR == 2015')\n",
    "cds_train = cds_dummy.query('YEAR < 2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = cds_train.drop(['MAIS3+'], axis = 1)\n",
    "y_train = cds_train['MAIS3+']\n",
    "X_test = cds_test.drop(['MAIS3+'], axis = 1)\n",
    "y_test = cds_test['MAIS3+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(predict).count(0)\n",
    "list(predict).count(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 標準化\n",
    "量的データを平均0分散1に標準化  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_col = ['YEAR', \\\n",
    "           'MODELYR', 'CARGOWGT','CURBWGT', 'SPLIMIT', 'TRAVELSP', 'VEHWGT', 'WGTCDTR', 'WHLDRWHL','otvehwgt', 'DVTOTAL', \\\n",
    "           'ORIGAVTW', 'WHEELBAS', \\\n",
    "           'ODOMETER', \\\n",
    "           'AGE', 'HEIGHT', 'WEIGHT', \\\n",
    "           'otbsp']\n",
    "scaler = StandardScaler(copy = True, with_mean = True)\n",
    "scaler.fit(X_train[st_col])\n",
    "X_train_st = pd.DataFrame(scaler.transform(X_train[st_col]), columns = st_col)\n",
    "X_test_st = pd.DataFrame(scaler.transform(X_test[st_col]), columns = st_col)\n",
    "X_train = X_train.reset_index(drop = True)\n",
    "y_train = y_train.reset_index(drop = True)\n",
    "X_test = X_test.reset_index(drop = True)\n",
    "y_test = y_test.reset_index(drop = True)\n",
    "X_train[st_col] = X_train_st\n",
    "X_test[st_col] = X_test_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lassoで特徴量選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv = linear_model.LassoCV(alphas = 10 ** np.arange(-6, 1, 0.1), cv = 5)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "print(lasso_cv.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in uyear:\n",
    "    X_train['ADAPTEQ'] = X_train['ADAPTEQ'].astype(np.int64)\n",
    "    X_train['COLUMTYP'] = X_train['COLUMTYP'].astype(np.int64)\n",
    "    X_train['SEATRACK'] = X_train['SEATRACK'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso_cv.score(X_test, y_test)\n",
    "lasso_cv.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_df = pd.DataFrame({'Feature' : list(X_train.columns.values),\n",
    "                     'coef' : lasso_cv.coef_})\n",
    "f_df = f_df.sort_values('coef', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f_df[f_df.coef != 0])\n",
    "len(f_df)\n",
    "selected_f = list(f_df[f_df.coef != 0]['Feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s = X_train[selected_f]\n",
    "X_test_s = X_test[selected_f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 選択した特徴量で再度ランダムフォレストで推定 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators = 100, random_state = 0, max_depth = 100)\n",
    "forest.fit(X_train_s, y_train)\n",
    "predict = forest.predict(X_test_s)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predict, pos_label = 1)\n",
    "print('auc:', auc(fpr, tpr))\n",
    "print('accuracy', accuracy_score(predict, y_test))\n",
    "fti = forest.feature_importances_\n",
    "columns = list(X_train_s.columns.values)\n",
    "im_df = pd.DataFrame({'Feature':columns,\n",
    "                     'importance':fti})\n",
    "im_df = im_df.sort_values('importance', ascending = False)\n",
    "im_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1正則化ロジスティック回帰で推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_param = {'C': [0.06], 'solver': ['liblinear']}\n",
    "grid_search = GridSearchCV(LogisticRegression(random_state = 0, penalty = 'l1'), grid_param, cv = 5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('best parameter:', grid_search.best_params_)\n",
    "predict = grid_search.predict(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predict, pos_label = 1)\n",
    "print('auc:', auc(fpr, tpr))\n",
    "print('accuracy:', accuracy_score(predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_df = pd.DataFrame({'Feature' : list(X_train.columns.values),\n",
    "                     'coef' : grid_search.best_estimator_.coef_[0]})\n",
    "f_df = f_df.sort_values('coef', ascending = False)\n",
    "F_df = f_df.sort_values('coef', ascending = True)\n",
    "f_df.head(50)\n",
    "F_df.head(70)\n",
    "log_s_f = list(f_df[f_df.coef != 0]['Feature'])\n",
    "len(f_df)\n",
    "len(log_s_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 係数を絶対値で表記しソート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_abs = lambda x: -x if x < 0 else x\n",
    "f_abs = f_df\n",
    "f_abs['coef'] = f_abs['coef'].map(df_abs)\n",
    "a_abs = f_abs.sort_values('coef', ascending = False)\n",
    "f_abs.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 選択した特徴量で再度ランダムフォレストで推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_param = {'n_estimators': [400], 'max_depth': [100]}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state = 0), grid_param, cv = 5)\n",
    "grid_search.fit(X_train_s, y_train)\n",
    "predict = grid_search.predict(X_test_s)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predict, pos_label = 1)\n",
    "print('best parameter:', grid_search.best_params_)\n",
    "print('auc:', auc(fpr, tpr))\n",
    "print('accuracy', accuracy_score(predict, y_test))\n",
    "fti = grid_search.best_estimator_.feature_importances_\n",
    "columns = list(X_train_s.columns.values)\n",
    "im_df = pd.DataFrame({'Feature':columns,\n",
    "                     'importance':fti})\n",
    "im_df = im_df.sort_values('importance', ascending = False)\n",
    "im_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {'alphas' : [0.001, 0.01, 0.1, 1, 10]}\n",
    "lasso_cv = GridSearchCV(Lasso(random_state = 0, clas))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
